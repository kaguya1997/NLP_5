{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca48a7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from opencc import OpenCC\n",
    "from keras.layers import Input, LSTM, Dense, merge,concatenate\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from keras.models import Model,load_model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322e91a3",
   "metadata": {},
   "source": [
    "### 可由此開始跳過到最下面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cf14e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'translation2019zh_train.json'\n",
    "valid_file = 'translation2019zh_valid.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6247476d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "train_contents = open(train_file, encoding=\"utf-8\")\n",
    "train_len = len(train_contents.readlines()) / 1000\n",
    "train_contents = open(train_file, encoding=\"utf-8\")\n",
    "for i, train_content in enumerate(train_contents.readlines()):\n",
    "    if i == int(train_len):\n",
    "        break\n",
    "    temp = json.loads(train_content)\n",
    "    train_data.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881af298",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9162bf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = []\n",
    "valid_contents = open(valid_file, encoding=\"utf-8\")\n",
    "for valid_content in valid_contents.readlines():\n",
    "    temp = json.loads(valid_content)\n",
    "    valid_data.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91e50812",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = OpenCC('s2t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27e4b1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_data:\n",
    "    i['chinese'] = cc.convert(i['chinese'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab70952",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in valid_data:\n",
    "    i['chinese'] = cc.convert(i['chinese'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03486163",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_file = '1by1000_train_data_cc.txt'\n",
    "f = open(txt_file, 'w', encoding = 'utf-8')\n",
    "temp = int(len(train_data))\n",
    "for count, i in enumerate(train_data):\n",
    "    if count == temp:\n",
    "        break\n",
    "    f.writelines(i['english'] + '\\t' + i['chinese'] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "374ca39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SAMPLES=500  #樣本數\n",
    "batch_size = 64\n",
    "epochs = 1000\n",
    "latent_dim = 256 # LSTM單元數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5073fb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_file = '1by1000_train_data_cc.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f8f7336",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = txt_file\n",
    "df = pd.read_table(data_path,header=None, error_bad_lines=False).iloc[:NUM_SAMPLES,0:2]\n",
    "df.columns = ['inputs','targets']\n",
    "df['targets'] = df['targets'].apply(lambda x:'\\t'+x+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd5906b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成列表\n",
    "input_texts = df.inputs.values.tolist()\n",
    "target_texts = df.targets.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f43d837",
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成字典\n",
    "input_characters = sorted(list(set(df.inputs.unique().sum())))\n",
    "target_characters = sorted(list(set(df.targets.unique().sum())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00e890d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "INUPT_LENGTH = max([ len(txt) for txt in input_texts])\n",
    "OUTPUT_LENGTH = max([ len(txt) for txt in target_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "027ca87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#向量化\n",
    "input_token_index = dict( [(char, i)for i, char in enumerate(input_characters)] )\n",
    "target_token_index = dict( [(char, i) for i, char in enumerate(target_characters)] )\n",
    "reverse_input_char_index = dict([(i, char) for i, char in enumerate(input_characters)])\n",
    "reverse_target_char_index = dict([(i, char) for i, char in enumerate(target_characters)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08aab707",
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成三維輸入\n",
    "encoder_input_data = np.zeros((NUM_SAMPLES,INUPT_LENGTH,num_encoder_tokens))\n",
    "decoder_input_data = np.zeros((NUM_SAMPLES,OUTPUT_LENGTH,num_decoder_tokens))\n",
    "decoder_target_data  = np.zeros((NUM_SAMPLES,OUTPUT_LENGTH,num_decoder_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1843e99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,(input_text,target_text) in enumerate(zip(input_texts,target_texts)):\n",
    "    for t,char in enumerate(input_text):\n",
    "        encoder_input_data[i,t,input_token_index[char]]=1.0\n",
    "    for t, char in enumerate(target_text):\n",
    "        decoder_input_data[i,t,target_token_index[char]]=1.0\n",
    "        if t > 0:\n",
    "            decoder_target_data[i, t-1, target_token_index[char]] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33071c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    encoder_inputs = Input(shape = (None,num_encoder_tokens))\n",
    "    encoder = LSTM(latent_dim,return_state = True)\n",
    "    encoder_outputs,state_h,state_c = encoder(encoder_inputs)\n",
    "    encoder_state = [state_h,state_c]\n",
    "    decoder_inputs = Input(shape = (None,num_decoder_tokens))\n",
    "    decoder_lstm = LSTM(latent_dim,return_state = True,return_sequences = True)\n",
    "    decoder_outputs,_,_ = decoder_lstm(decoder_inputs,initial_state = encoder_state)\n",
    "    decoder_dense = Dense(num_decoder_tokens,activation = 'softmax')\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    model = Model([encoder_inputs,decoder_inputs],decoder_outputs)\n",
    "    encoder_model = Model(encoder_inputs,encoder_state)\n",
    "    decoder_state_input_h = Input(shape = (latent_dim,))\n",
    "    decoder_state_input_c = Input(shape = (latent_dim,))\n",
    "    decoder_state_inputs = [decoder_state_input_h,decoder_state_input_c]\n",
    "    decoder_outputs,state_h,state_c = decoder_lstm(decoder_inputs,initial_state = decoder_state_inputs)\n",
    "    decoder_states = [state_h,state_c]\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = Model([decoder_inputs] + decoder_state_inputs,[decoder_outputs] + decoder_states)\n",
    "    plot_model(model = model,show_shapes = True)\n",
    "    plot_model(model = encoder_model,show_shapes = True)\n",
    "    plot_model(model = decoder_model,show_shapes = True)\n",
    "    return model,encoder_model,decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2938dd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq,encoder_model,decoder_model):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "        if sampled_char == '\\n' or len(decoded_sentence) >INUPT_LENGTH  :\n",
    "            stop_condition = True\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "        states_value = [h, c]\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fa27b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model,encoder_model,decoder_model=create_model()\n",
    "    model.compile(optimizer='rmsprop',loss='categorical_crossentropy')\n",
    "    model.fit([encoder_input_data,decoder_input_data],decoder_target_data,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_split=0.2)\n",
    "    model.save('s2s_1000epo.h5')\n",
    "    encoder_model.save('encoder_model_1000epo.h5')\n",
    "    decoder_model.save('decoder_model_1000epo.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d9b12b",
   "metadata": {},
   "source": [
    "### 至此"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d7a784",
   "metadata": {},
   "source": [
    "有 encoder_model_1000epo.h5 及 decoder_model_1000epo.h5 後，\n",
    "執行下一格並輸入test即可測試。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bd53931",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select train model or test model:test\n",
      "testing.........\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-ad6658a247ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"testing.........\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mwhile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-ad6658a247ef>\u001b[0m in \u001b[0;36mtest\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mencoder_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'encoder_model_1000epo.h5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mdecoder_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'decoder_model_1000epo.h5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"請輸入要翻譯的英文:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mss\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'-1'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m    858\u001b[0m                 \u001b[1;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m             )\n\u001b[1;32m--> 860\u001b[1;33m         return self._input_request(str(prompt),\n\u001b[0m\u001b[0;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m    902\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    903\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 904\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Interrupted by user\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    905\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid Message:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    encoder_model=load_model('encoder_model_1000epo.h5', compile=False) \n",
    "    decoder_model=load_model('decoder_model_1000epo.h5', compile=False)\n",
    "    ss=input(\"請輸入要翻譯的英文:\")\n",
    "    if ss=='-1':\n",
    "        sys.exit()\n",
    "    input_seq=np.zeros((1,INUPT_LENGTH,num_encoder_tokens)) \n",
    "    for t,char in enumerate(ss):\n",
    "        input_seq[0,t,input_token_index[char]]=1.0\n",
    "    decoded_sentence = decode_sequence(input_seq,encoder_model,decoder_model)\n",
    "    print('-')\n",
    "    print('Decoded sentence:', decoded_sentence)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    intro=input(\"select train model or test model:\")\n",
    "    if intro==\"train\":\n",
    "        print(\"training...........\")\n",
    "        train()\n",
    "    else:\n",
    "        print(\"testing.........\")\n",
    "        while(1):\n",
    "            test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db9ba2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
